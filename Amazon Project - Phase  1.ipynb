{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4b47aa5",
   "metadata": {},
   "source": [
    "## **Project :-  Amazon Product Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ea9df7",
   "metadata": {},
   "source": [
    "### Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e80eaa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import necessary libraries\n",
    "import re\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Let's import necessary library for validating the url's\n",
    "import validators\n",
    "import time\n",
    "\n",
    "# SQL server Library\n",
    "import pyodbc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac6ae92",
   "metadata": {},
   "source": [
    "### Declaring Path & Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "691779c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project Folder Path\n",
    "project_path = r\"C:\\\\Users\\\\Futurense\\\\Desktop\\\\Team Project - Amazon\"\n",
    "\n",
    "# Let's define folder path\n",
    "folder_path = f\"{project_path}\\\\data\"\n",
    "\n",
    "# Clean File Name\n",
    "clean_file = \"amazon_csv_cleaned.csv\"\n",
    "\n",
    "# driver = \"ODBC Driver 18 for SQL Server\"\n",
    "driver = \"SQL Server\"\n",
    "server = \"DESKTOP-TOEPTEF\\SQL_SERVER\"\n",
    "port = 1433\n",
    "\n",
    "# Database Name\n",
    "db_name = \"AmazonDB\"\n",
    "\n",
    "# table_name\n",
    "table_name='amazon_product_v1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801b4421",
   "metadata": {},
   "source": [
    "### Validate Columns between Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ae96228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path_recurs(folder_path: str) :\n",
    "    \"\"\"\n",
    "    Generator to generate the filepath\n",
    "    \n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for filename in files:\n",
    "            p = os.path.join(root, filename)\n",
    "            yield p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2299fb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_names(folder_path: str) -> list:\n",
    "    \"\"\"\n",
    "    Function to get list of column names inside the csv files\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for p in  get_path_recurs(folder_path):\n",
    "        with open(p, encoding=\"mbcs\") as f:\n",
    "            row = [p] # Create a list with the file path\n",
    "            record = f.readlines(1)[0].strip().split(',') # Read the first line, remove leading/trailing whitespaces, and split by commas\n",
    "            row.append(len(record)) # Append the length of the record list to the row list\n",
    "            row.extend(record) # Extend the row list with individual values from the record list\n",
    "            rows.append(row) # Append the row list to the rows list\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bc6c79a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\\\Users\\\\Futurense\\\\Desktop\\\\Team Project - ...</td>\n",
       "      <td>9</td>\n",
       "      <td>name</td>\n",
       "      <td>main_category</td>\n",
       "      <td>sub_category</td>\n",
       "      <td>image</td>\n",
       "      <td>link</td>\n",
       "      <td>ratings</td>\n",
       "      <td>no_of_ratings</td>\n",
       "      <td>discount_price</td>\n",
       "      <td>actual_price</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\\\Users\\\\Futurense\\\\Desktop\\\\Team Project - ...</td>\n",
       "      <td>9</td>\n",
       "      <td>name</td>\n",
       "      <td>main_category</td>\n",
       "      <td>sub_category</td>\n",
       "      <td>image</td>\n",
       "      <td>link</td>\n",
       "      <td>ratings</td>\n",
       "      <td>no_of_ratings</td>\n",
       "      <td>discount_price</td>\n",
       "      <td>actual_price</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\\\Users\\\\Futurense\\\\Desktop\\\\Team Project - ...</td>\n",
       "      <td>9</td>\n",
       "      <td>name</td>\n",
       "      <td>main_category</td>\n",
       "      <td>sub_category</td>\n",
       "      <td>image</td>\n",
       "      <td>link</td>\n",
       "      <td>ratings</td>\n",
       "      <td>no_of_ratings</td>\n",
       "      <td>discount_price</td>\n",
       "      <td>actual_price</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  0   1     2              3   \\\n",
       "0  C:\\\\Users\\\\Futurense\\\\Desktop\\\\Team Project - ...   9  name  main_category   \n",
       "1  C:\\\\Users\\\\Futurense\\\\Desktop\\\\Team Project - ...   9  name  main_category   \n",
       "2  C:\\\\Users\\\\Futurense\\\\Desktop\\\\Team Project - ...   9  name  main_category   \n",
       "\n",
       "             4      5     6        7              8               9   \\\n",
       "0  sub_category  image  link  ratings  no_of_ratings  discount_price   \n",
       "1  sub_category  image  link  ratings  no_of_ratings  discount_price   \n",
       "2  sub_category  image  link  ratings  no_of_ratings  discount_price   \n",
       "\n",
       "             10    11  \n",
       "0  actual_price  None  \n",
       "1  actual_price  None  \n",
       "2  actual_price  None  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We are getting column names from all CSV file and storing in DataFrame for comparision\n",
    "\n",
    "rows = get_col_names(folder_path)\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c76988a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>name</td>\n",
       "      <td>main_category</td>\n",
       "      <td>sub_category</td>\n",
       "      <td>image</td>\n",
       "      <td>link</td>\n",
       "      <td>ratings</td>\n",
       "      <td>no_of_ratings</td>\n",
       "      <td>discount_price</td>\n",
       "      <td>actual_price</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>name</td>\n",
       "      <td>main_category</td>\n",
       "      <td>sub_category</td>\n",
       "      <td>image</td>\n",
       "      <td>link</td>\n",
       "      <td>ratings</td>\n",
       "      <td>no_of_ratings</td>\n",
       "      <td>discount_price</td>\n",
       "      <td>actual_price</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      2              3              4             5      6        7   \\\n",
       "0   name  main_category   sub_category         image   link  ratings   \n",
       "10                 name  main_category  sub_category  image     link   \n",
       "\n",
       "               8               9               10            11  \n",
       "0   no_of_ratings  discount_price    actual_price          None  \n",
       "10        ratings   no_of_ratings  discount_price  actual_price  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We are checking whether columns are same by dropping duplicate columns\n",
    "\n",
    "df.iloc[:, 2:].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a80a643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\\\\\Users\\\\\\\\Futurense\\\\\\\\Desktop\\\\\\\\Team Project - Amazon\\\\data\\\\Amazon-Products.csv'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[10][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00817bcc",
   "metadata": {},
   "source": [
    "**Observations: -**\n",
    "\n",
    "From above analysis, we could see there is some **discrepancy in col numbers in 10 th row** and all other csv have same columns.\n",
    "\n",
    "And could see there is empty column in **'Amazon-Product.csv' file**.\n",
    "\n",
    "On checking we found that It has additional Index col.\n",
    "\n",
    "On further checking it seems like **'Amazon-Product.csv' already contain complete data**.\n",
    "\n",
    "But we need to cross check with other csv as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44040c8",
   "metadata": {},
   "source": [
    "#### Check If files were already appended in Amazon-Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00b35736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_all_files(file_list: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function to concat all CSV file to DataFrame\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    for p in file_list:\n",
    "        my_df = pd.read_csv(p)\n",
    "        frames.append(my_df)\n",
    "    DF = pd.concat(frames)\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21dce94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting list of files except Amazon-Products\n",
    "\n",
    "file_list = [p for p in get_path_recurs(folder_path) if \"Amazon-Products.csv\" not in p]\n",
    "\n",
    "# Read all csv except \"Amazon-Products.csv\" and convert to DF\n",
    "DF = concat_all_files(file_list)\n",
    "\n",
    "# Reading Amazon-Products\n",
    "my_df = pd.read_csv(f\"{folder_path}\\Amazon-Products.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1da3d1",
   "metadata": {},
   "source": [
    "**Note : -** \n",
    "\n",
    "**DF** --> Concated CSV files except 'Amazon-Products.csv'\n",
    "\n",
    "**my_df** --> 'Amazon-Products.csv' to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68f20b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(551585, 9)\n",
      "(551585, 9)\n"
     ]
    }
   ],
   "source": [
    "# Checking the shape of both DataFrame\n",
    "print(DF.shape)\n",
    "print(my_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc8bd3e",
   "metadata": {},
   "source": [
    "From above we could see both **DataFrame have same shape**, but we have to verify whether data is all same between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87c587a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_series(obj: pd.Series) -> str:\n",
    "    \"\"\"\n",
    "    Function to concat series values to string\n",
    "    \"\"\"\n",
    "    l = [str(i) for i in obj.values]\n",
    "    return \"\".join(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4fdf6f",
   "metadata": {},
   "source": [
    "**Approach to compare**\n",
    "\n",
    "To compare data between two DF, we will first concat all rows and create a new column. Then compare concatenated columns between DataFrames, thus if there is any difference in data between them we can findout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b8fdff0",
   "metadata": {},
   "outputs": [],
   "source": [
    " def create_concat_col(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Concat all rows to new column and sort them\n",
    "    \"\"\"\n",
    "    df[\"sorter\"] = df.apply(lambda x: concat_series(x), axis=1)\n",
    "    df = df.sort_values(\"sorter\").reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a6c45cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = create_concat_col(my_df)\n",
    "DF = create_concat_col(DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "645dec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matching only the concated records to find differences\n",
    "my_df[\"is_match\"] = my_df[\"sorter\"] == DF[\"sorter\"]\n",
    "DF[\"is_match\"] = my_df[\"sorter\"] == DF[\"sorter\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97e03dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The No of non-matcing : 0\n"
     ]
    }
   ],
   "source": [
    "# To Check mismatches\n",
    "print(f\"The No of non-matcing : {len(my_df[~my_df['is_match']])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5afad56",
   "metadata": {},
   "source": [
    "From above analysis, We could see all **data merged except 'Amazon-Products.csv' is same as 'Amazon-Products.csv' file** as per our assumption\n",
    "\n",
    "So while reading we need to read file only from 'Amazon-Products.csv' file\n",
    "\n",
    "So from now on we'll consider 'Amazon-Products.csv' as main DataFrame and continue working on it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393f2201",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14eb711",
   "metadata": {},
   "source": [
    "#### Let's read only Amazon-Products.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2833108a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{folder_path}\\Amazon-Products.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69ebf769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>main_category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>image</th>\n",
       "      <th>link</th>\n",
       "      <th>ratings</th>\n",
       "      <th>no_of_ratings</th>\n",
       "      <th>discount_price</th>\n",
       "      <th>actual_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lloyd 1.5 Ton 3 Star Inverter Split Ac (5 In 1...</td>\n",
       "      <td>appliances</td>\n",
       "      <td>Air Conditioners</td>\n",
       "      <td>https://m.media-amazon.com/images/I/31UISB90sY...</td>\n",
       "      <td>https://www.amazon.in/Lloyd-Inverter-Convertib...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2,255</td>\n",
       "      <td>₹32,999</td>\n",
       "      <td>₹58,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LG 1.5 Ton 5 Star AI DUAL Inverter Split AC (C...</td>\n",
       "      <td>appliances</td>\n",
       "      <td>Air Conditioners</td>\n",
       "      <td>https://m.media-amazon.com/images/I/51JFb7FctD...</td>\n",
       "      <td>https://www.amazon.in/LG-Convertible-Anti-Viru...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2,948</td>\n",
       "      <td>₹46,490</td>\n",
       "      <td>₹75,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LG 1 Ton 4 Star Ai Dual Inverter Split Ac (Cop...</td>\n",
       "      <td>appliances</td>\n",
       "      <td>Air Conditioners</td>\n",
       "      <td>https://m.media-amazon.com/images/I/51JFb7FctD...</td>\n",
       "      <td>https://www.amazon.in/LG-Inverter-Convertible-...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1,206</td>\n",
       "      <td>₹34,490</td>\n",
       "      <td>₹61,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name main_category  \\\n",
       "0  Lloyd 1.5 Ton 3 Star Inverter Split Ac (5 In 1...    appliances   \n",
       "1  LG 1.5 Ton 5 Star AI DUAL Inverter Split AC (C...    appliances   \n",
       "2  LG 1 Ton 4 Star Ai Dual Inverter Split Ac (Cop...    appliances   \n",
       "\n",
       "       sub_category                                              image  \\\n",
       "0  Air Conditioners  https://m.media-amazon.com/images/I/31UISB90sY...   \n",
       "1  Air Conditioners  https://m.media-amazon.com/images/I/51JFb7FctD...   \n",
       "2  Air Conditioners  https://m.media-amazon.com/images/I/51JFb7FctD...   \n",
       "\n",
       "                                                link ratings no_of_ratings  \\\n",
       "0  https://www.amazon.in/Lloyd-Inverter-Convertib...     4.2         2,255   \n",
       "1  https://www.amazon.in/LG-Convertible-Anti-Viru...     4.2         2,948   \n",
       "2  https://www.amazon.in/LG-Inverter-Convertible-...     4.2         1,206   \n",
       "\n",
       "  discount_price actual_price  \n",
       "0        ₹32,999      ₹58,990  \n",
       "1        ₹46,490      ₹75,990  \n",
       "2        ₹34,490      ₹61,990  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see top 3 rows of the dataset\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83790de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the amazon-data.csv file is : - (551585, 9)\n"
     ]
    }
   ],
   "source": [
    "# Let's check the shape of the data\n",
    "\n",
    "print(f\"Shape of the amazon-data.csv file is : - {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "676241aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 551585 entries, 0 to 1103\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   name            551585 non-null  object\n",
      " 1   main_category   551585 non-null  object\n",
      " 2   sub_category    551585 non-null  object\n",
      " 3   image           551585 non-null  object\n",
      " 4   link            551585 non-null  object\n",
      " 5   ratings         375791 non-null  object\n",
      " 6   no_of_ratings   375791 non-null  object\n",
      " 7   discount_price  490422 non-null  object\n",
      " 8   actual_price    533772 non-null  object\n",
      "dtypes: object(9)\n",
      "memory usage: 42.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Let's check about the information of the data\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9887749",
   "metadata": {},
   "source": [
    "**As we can see from above information of the data that : 'ratings', 'no_of_ratings', 'discount_price' & 'actual_price'  columns are having the object datatype which should be integer or float, so we need to check the inconsistency in these columns.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84af349",
   "metadata": {},
   "source": [
    "### Data Consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b4bb28",
   "metadata": {},
   "source": [
    "#### Numeric Data Inconsistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fb81e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['4.2', '4.0', '4.1', '4.3', '3.9', '3.8', '3.5', nan, '4.6', '3.3',\n",
       "       '3.4', '3.7', '2.9', '5.0', '4.4', '3.6', '2.7', '4.5', '3.0',\n",
       "       '3.1', '3.2', '4.8', '4.7', '2.5', '1.0', '2.6', '2.8', '2.3',\n",
       "       '1.7', 'Get', '1.8', '2.4', '4.9', '2.2', '1.6', '1.9', '2.0',\n",
       "       '1.4', '2.1', 'FREE', '1.2', '1.3', '1.5', '₹68.99', '₹65', '1.1',\n",
       "       '₹70', '₹100', '₹99', '₹2.99'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let' check the unique values in the ratings ,no_of_ratings, discount_price & actual_price columns\n",
    "\n",
    "\n",
    "# Let's first work on the ratings column \n",
    "\n",
    "df['ratings'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c5416f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to parse rating data\n",
    "\n",
    "df[\"corrected_rating\"] = pd.to_numeric(df[\"ratings\"], 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a7aacdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check how many non-NaN rating data converted to NaN\n",
    "\n",
    "non_corrected = df[df[\"corrected_rating\"].isna() & ~df[\"ratings\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a46d2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6233, 10)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the shape of the non_corrected values\n",
    "\n",
    "non_corrected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77f805c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Get', 'FREE', '₹68.99', '₹65', '₹70', '₹100', '₹99', '₹2.99'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see unusual unique value counts, in rating column which must needed to be removed from the column \n",
    "# to make that column as a numerical column.\n",
    "\n",
    "non_corrected[\"ratings\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a56a816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Get       4852\n",
       "FREE      1357\n",
       "₹99         14\n",
       "₹70          5\n",
       "₹2.99        2\n",
       "₹68.99       1\n",
       "₹65          1\n",
       "₹100         1\n",
       "Name: ratings, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the value count\n",
    "\n",
    "non_corrected[\"ratings\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa9f6ec",
   "metadata": {},
   "source": [
    "**From above data, it is seen than ratings col contains invalid data like rupees, and others\n",
    "Since those data doesn't make any sense to rating we will be making it null**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bbce70a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_numbers(string: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert ₹ and ,   to normal string\n",
    "    \"\"\"\n",
    "    if isinstance(string, float) and np.isnan(string):\n",
    "        return string\n",
    "    \n",
    "    res = string.replace(\",\", \"\")\n",
    "    res = res.replace(\"₹\", \"\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "505f7e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to parse rating data\n",
    "\n",
    "df[\"t_discount_price\"] = pd.to_numeric(df[\"discount_price\"].apply(lambda x: format_numbers(x)), 'coerce')\n",
    "df[\"t_actual_price\"] = pd.to_numeric(df[\"actual_price\"].apply(lambda x: format_numbers(x)), 'coerce')\n",
    "df[\"t_no_of_ratings\"] = pd.to_numeric(df[\"no_of_ratings\"].apply(lambda x: format_numbers(x)), 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "847f5fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>main_category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>image</th>\n",
       "      <th>link</th>\n",
       "      <th>ratings</th>\n",
       "      <th>no_of_ratings</th>\n",
       "      <th>discount_price</th>\n",
       "      <th>actual_price</th>\n",
       "      <th>corrected_rating</th>\n",
       "      <th>t_discount_price</th>\n",
       "      <th>t_actual_price</th>\n",
       "      <th>t_no_of_ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, main_category, sub_category, image, link, ratings, no_of_ratings, discount_price, actual_price, corrected_rating, t_discount_price, t_actual_price, t_no_of_ratings]\n",
       "Index: []"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check how many non-NaN rating data converted to NaN\n",
    "\n",
    "df[df[\"t_discount_price\"].isna() & ~df[\"discount_price\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14faecd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>main_category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>image</th>\n",
       "      <th>link</th>\n",
       "      <th>ratings</th>\n",
       "      <th>no_of_ratings</th>\n",
       "      <th>discount_price</th>\n",
       "      <th>actual_price</th>\n",
       "      <th>corrected_rating</th>\n",
       "      <th>t_discount_price</th>\n",
       "      <th>t_actual_price</th>\n",
       "      <th>t_no_of_ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, main_category, sub_category, image, link, ratings, no_of_ratings, discount_price, actual_price, corrected_rating, t_discount_price, t_actual_price, t_no_of_ratings]\n",
       "Index: []"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check how many non-NaN rating data converted to NaN\n",
    "\n",
    "df[df[\"t_actual_price\"].isna() & ~df[\"actual_price\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd0cf1e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>main_category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>image</th>\n",
       "      <th>link</th>\n",
       "      <th>ratings</th>\n",
       "      <th>no_of_ratings</th>\n",
       "      <th>discount_price</th>\n",
       "      <th>actual_price</th>\n",
       "      <th>corrected_rating</th>\n",
       "      <th>t_discount_price</th>\n",
       "      <th>t_actual_price</th>\n",
       "      <th>t_no_of_ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>Daikin 1.8 Ton 3 Star Inverter Split Ac (Coppe...</td>\n",
       "      <td>appliances</td>\n",
       "      <td>Air Conditioners</td>\n",
       "      <td>https://m.media-amazon.com/images/I/51hn7NHS3T...</td>\n",
       "      <td>https://www.amazon.in/Daikin-Inverter-Copper-F...</td>\n",
       "      <td>Get</td>\n",
       "      <td>Only 2 left in stock.</td>\n",
       "      <td>₹59,979</td>\n",
       "      <td>₹72,900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59979.0</td>\n",
       "      <td>72900.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>Master Electronic provides Window AC 3-Star 1....</td>\n",
       "      <td>appliances</td>\n",
       "      <td>Air Conditioners</td>\n",
       "      <td>https://m.media-amazon.com/images/I/41B0LWORAr...</td>\n",
       "      <td>https://www.amazon.in/Master-Electronic-provid...</td>\n",
       "      <td>Get</td>\n",
       "      <td>Only 1 left in stock.</td>\n",
       "      <td>₹36,999</td>\n",
       "      <td>₹39,999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36999.0</td>\n",
       "      <td>39999.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>Master Electronic provides 1.5 Ton 3 Star Dust...</td>\n",
       "      <td>appliances</td>\n",
       "      <td>Air Conditioners</td>\n",
       "      <td>https://m.media-amazon.com/images/I/61yVE5P7FU...</td>\n",
       "      <td>https://www.amazon.in/Master-Electronic-provid...</td>\n",
       "      <td>Get</td>\n",
       "      <td>Only 1 left in stock.</td>\n",
       "      <td>₹36,999</td>\n",
       "      <td>₹39,666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36999.0</td>\n",
       "      <td>39666.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  name main_category  \\\n",
       "437  Daikin 1.8 Ton 3 Star Inverter Split Ac (Coppe...    appliances   \n",
       "473  Master Electronic provides Window AC 3-Star 1....    appliances   \n",
       "474  Master Electronic provides 1.5 Ton 3 Star Dust...    appliances   \n",
       "\n",
       "         sub_category                                              image  \\\n",
       "437  Air Conditioners  https://m.media-amazon.com/images/I/51hn7NHS3T...   \n",
       "473  Air Conditioners  https://m.media-amazon.com/images/I/41B0LWORAr...   \n",
       "474  Air Conditioners  https://m.media-amazon.com/images/I/61yVE5P7FU...   \n",
       "\n",
       "                                                  link ratings  \\\n",
       "437  https://www.amazon.in/Daikin-Inverter-Copper-F...     Get   \n",
       "473  https://www.amazon.in/Master-Electronic-provid...     Get   \n",
       "474  https://www.amazon.in/Master-Electronic-provid...     Get   \n",
       "\n",
       "             no_of_ratings discount_price actual_price  corrected_rating  \\\n",
       "437  Only 2 left in stock.        ₹59,979      ₹72,900               NaN   \n",
       "473  Only 1 left in stock.        ₹36,999      ₹39,999               NaN   \n",
       "474  Only 1 left in stock.        ₹36,999      ₹39,666               NaN   \n",
       "\n",
       "     t_discount_price  t_actual_price  t_no_of_ratings  \n",
       "437           59979.0         72900.0              NaN  \n",
       "473           36999.0         39999.0              NaN  \n",
       "474           36999.0         39666.0              NaN  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check how many non-NaN rating data converted to NaN\n",
    "\n",
    "non_corrected_vals = df[df[\"t_no_of_ratings\"].isna() & ~df[\"no_of_ratings\"].isna()]\n",
    "non_corrected_vals.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3c9fd1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FREE Delivery by Amazon                           3296\n",
       "Only 1 left in stock.                             1050\n",
       "Usually dispatched in 3 to 4 weeks.                847\n",
       "Only 2 left in stock.                              562\n",
       "Usually dispatched in 4 to 5 days.                 190\n",
       "Usually dispatched in 5 to 6 days.                  70\n",
       "Usually dispatched in 6 to 7 days.                  45\n",
       "Usually dispatched in 7 to 8 days.                  42\n",
       "Only 3 left in stock.                               34\n",
       "Only 5 left in stock.                               29\n",
       "Only 4 left in stock.                               22\n",
       "Usually dispatched in 11 to 12 days.                17\n",
       "Usually dispatched in 2 to 3 weeks.                  8\n",
       "Usually dispatched in 4 to 5 weeks.                  8\n",
       "Usually dispatched in 2 to 3 days.                   6\n",
       "Usually dispatched in 3 to 5 days.                   3\n",
       "Usually dispatched in 9 to 10 days.                  1\n",
       "Usually dispatched in 8 to 9 days.                   1\n",
       "Usually dispatched in 1 to 2 months.                 1\n",
       "This item will be released on August 14, 2023.       1\n",
       "Name: no_of_ratings, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the value counts of the column\n",
    "\n",
    "non_corrected_vals[\"no_of_ratings\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4d25e7",
   "metadata": {},
   "source": [
    "**As per above analysis, We could see that there are 6233 records are having invalid no_of_ratings, i.e They contain text data which informs delivery status, So we am considerring them as NULL since they are not realted to rating information.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a0865422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_numbers(string: str, is_price: bool=False ) -> str:\n",
    "    '''\n",
    "    Replacing ',' and '₹' symbols to a proper numberic string.\n",
    "    Input: string - str - Like discount_price, actual_price, no_of_ratings, ratings.\n",
    "           is_price - bool - False - Whether a given string is price.?\n",
    "    Output: It will return a str with numbers.\n",
    "    '''\n",
    "    if isinstance(string, float) and np.isnan(string):\n",
    "        return string\n",
    "    \n",
    "    res = string.replace(\",\", \"\")\n",
    "    if is_price:\n",
    "        res = res.replace(\"₹\", \"\")\n",
    "    return res\n",
    "\n",
    "def covert_numeric_cols(df: pd.DataFrame, cols: list) -> None:\n",
    "    '''\n",
    "    It will convert string to number and overwrite the DataFrame.\n",
    "    Input: df - DataFrame \n",
    "           cols - list of columns\n",
    "    Output: None.\n",
    "    '''\n",
    "    for col in cols:\n",
    "        is_price = False\n",
    "        if 'price' in col:\n",
    "            is_price = True\n",
    "        df[col] = pd.to_numeric(df[col].apply(lambda x: format_numbers(x, is_price)), 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "618ca7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"discount_price\",\n",
    "       \"actual_price\",\n",
    "       \"no_of_ratings\",\n",
    "       \"ratings\"]\n",
    "covert_numeric_cols(df, cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8274d328",
   "metadata": {},
   "source": [
    "#### Categorical Data Inconsistency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d190430c",
   "metadata": {},
   "source": [
    "**Now lets explore the Categorical columns data to create the function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0582e2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['appliances', 'car & motorbike', 'tv, audio & cameras',\n",
       "       'sports & fitness', 'grocery & gourmet foods', 'home & kitchen',\n",
       "       'pet supplies', 'stores', 'toys & baby products', \"kids' fashion\",\n",
       "       'bags & luggage', 'accessories', \"women's shoes\",\n",
       "       'beauty & health', \"men's shoes\", \"women's clothing\",\n",
       "       'industrial supplies', \"men's clothing\", 'music',\n",
       "       'home, kitchen, pets'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's get the number of unique values\n",
    "print(df[\"main_category\"].nunique())\n",
    "\n",
    "# Let's get the unique values list\n",
    "df[\"main_category\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "39ad6db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Air Conditioners', 'All Appliances',\n",
       "       'All Car & Motorbike Products', 'All Electronics',\n",
       "       'All Exercise & Fitness', 'All Grocery & Gourmet Foods',\n",
       "       'All Home & Kitchen', 'All Pet Supplies',\n",
       "       'All Sports, Fitness & Outdoors', 'Amazon Fashion',\n",
       "       'Baby Bath, Skin & Grooming', 'Baby Fashion', 'Baby Products',\n",
       "       'Backpacks', 'Badminton', 'Bags & Luggage', 'Ballerinas',\n",
       "       'Beauty & Grooming', 'Bedroom Linen', 'Camera Accessories',\n",
       "       'Cameras', 'Camping & Hiking', 'Car & Bike Care',\n",
       "       'Car Accessories', 'Car Electronics', 'Car Parts',\n",
       "       'Cardio Equipment', 'Casual Shoes', 'Clothing',\n",
       "       'Coffee, Tea & Beverages', 'Cricket', 'Cycling', 'Diapers',\n",
       "       'Diet & Nutrition', 'Dog supplies', 'Ethnic Wear',\n",
       "       'Fashion & Silver Jewellery', 'Fashion Sales & Deals',\n",
       "       'Fashion Sandals', 'Fitness Accessories', 'Football',\n",
       "       'Formal Shoes', 'Furniture', 'Garden & Outdoors',\n",
       "       'Gold & Diamond Jewellery', 'Handbags & Clutches', 'Headphones',\n",
       "       'Health & Personal Care', 'Heating & Cooling Appliances',\n",
       "       'Home Audio & Theater', 'Home Décor', 'Home Entertainment Systems',\n",
       "       'Home Furnishing', 'Home Improvement', 'Home Storage',\n",
       "       'Household Supplies', 'Indoor Lighting',\n",
       "       'Industrial & Scientific Supplies', 'Innerwear',\n",
       "       'International Toy Store', 'Janitorial & Sanitation Supplies',\n",
       "       'Jeans', 'Jewellery', \"Kids' Clothing\", \"Kids' Fashion\",\n",
       "       \"Kids' Shoes\", \"Kids' Watches\", 'Kitchen & Dining',\n",
       "       'Kitchen & Home Appliances', 'Kitchen Storage & Containers',\n",
       "       'Lab & Scientific', 'Lingerie & Nightwear', 'Luxury Beauty',\n",
       "       'Make-up', \"Men's Fashion\", 'Motorbike Accessories & Parts',\n",
       "       'Musical Instruments & Professional Audio', 'Nursing & Feeding',\n",
       "       'Personal Care Appliances', 'Refrigerators',\n",
       "       'Refurbished & Open Box', 'Rucksacks', 'Running', 'School Bags',\n",
       "       'Security Cameras', 'Sewing & Craft Supplies', 'Shirts', 'Shoes',\n",
       "       'Snack Foods', 'Speakers', 'Sports Shoes', 'Sportswear',\n",
       "       'STEM Toys Store', 'Strength Training', 'Strollers & Prams',\n",
       "       'Suitcases & Trolley Bags', 'Sunglasses', 'T-shirts & Polos',\n",
       "       'Televisions', 'Test, Measure & Inspect', 'The Designer Boutique',\n",
       "       'Toys & Games', 'Toys Gifting Store', 'Travel Accessories',\n",
       "       'Travel Duffles', 'Value Bazaar', 'Wallets', 'Washing Machines',\n",
       "       'Watches', 'Western Wear', \"Women's Fashion\", 'Yoga'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's get the number of unique values\n",
    "print(df[\"sub_category\"].nunique())\n",
    "\n",
    "# Let's get the unique values list\n",
    "df[\"sub_category\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07be759",
   "metadata": {},
   "source": [
    "**On checking above string, we could see inconsistency in case and & So we create below function to standardize the text.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5de8affa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_word_consistency(x:str)->str:\n",
    "    \"\"\"\n",
    "    Text Standardization.\n",
    "    Input: str\n",
    "    output: str\n",
    "    \"\"\"\n",
    "    x=x.title().replace(\"Tv\", \"TV\").replace(\"&\", \"And\").replace(\"'S\", \"'s\")\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f8098db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Categorical columns to same format\n",
    "\n",
    "cols = [\"main_category\",\n",
    "       \"sub_category\"]\n",
    "for col in cols:\n",
    "    df[col] = df[col].apply(cat_word_consistency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c9c85d",
   "metadata": {},
   "source": [
    "### Data Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24111c9c",
   "metadata": {},
   "source": [
    "**URL Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3e2d8174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing URL to remove ref part\n",
    "df[\"link\"] = df[\"link\"].str.replace('/ref.*', '', regex=True).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674cc550",
   "metadata": {},
   "source": [
    "**On checking we could see last part in URL cotains sorting info, which after removal we could find duplicacies. Hence formating the URL to required part\n",
    ".**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f24b28",
   "metadata": {},
   "source": [
    "#### Price Dependency Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c49b3e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking valid Price data (ActualPrice > 0) and (DiscountPrice >= 0) and (ActualPrice > DiscountPrice)\n",
    "\n",
    "df[\"is_price_dependency_valid\"] = (df[\"actual_price\"] > 0) \\\n",
    "& (df[\"discount_price\"] >= 0) \\\n",
    "& (df[\"actual_price\"] > df[\"discount_price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "32034821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     490422\n",
       "False     61163\n",
       "Name: is_price_dependency_valid, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"is_price_dependency_valid\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d17e72",
   "metadata": {},
   "source": [
    "**As per above analysis, We could see 61163 have InValid price.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb58fb2",
   "metadata": {},
   "source": [
    "#### No of Rating Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c407a35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Valid no_of_rating conditions\n",
    "\n",
    "df[\"is_valid_no_of_ratings\"] = (df[\"no_of_ratings\"] >= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bd93f750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     369558\n",
       "False    182027\n",
       "Name: is_valid_no_of_ratings, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"is_valid_no_of_ratings\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f78b51",
   "metadata": {},
   "source": [
    "**But we could see 182027 rows with Invalid data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a54af73e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"is_valid_no_of_ratings\"] == False][\"no_of_ratings\"].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8414bbac",
   "metadata": {},
   "source": [
    "**On checking we could see all the Invalid records are NaN, we will handle NaN in Missing values secitons**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86cef23",
   "metadata": {},
   "source": [
    "#### Rating Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d2ef07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Rating valid condtion. i.e rating between 1 to 5, \n",
    "# also if no-of-rating is zero or Nan then Rating will be 0 which is valid case hence adding that condition as well\n",
    "\n",
    "df[\"is_rating_valid\"] = (df[\"ratings\"].between(1, 5) | ( (df[\"ratings\"] == 0) ) & ( (df[\"no_of_ratings\"] == 0) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3b0a953d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     369558\n",
       "False    182027\n",
       "Name: is_rating_valid, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"is_rating_valid\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699eb7e1",
   "metadata": {},
   "source": [
    "**In above code, we considered if all rating lies between 1 to 5, and if rating is 0 then no_of_ratings also should be zero since no review given.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a2edc63b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"is_rating_valid\"] == False][\"ratings\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc1d4d0",
   "metadata": {},
   "source": [
    "**On checking same as no_of_rating, we could see all the Invalid records are NaN, we will handle NaN in Missing values secitons.**\n",
    "\n",
    "**Also we could see the count of NaN is matching between no_of_rating and ratings, which means wherever no_of_rating is missing rating is also missing which is valid scenaario.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8338e6bc",
   "metadata": {},
   "source": [
    "### Duplcates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8677f47a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(551585, 16)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the shape of the data\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "251228ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(533511, 16)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping Duplicates among the same Category\n",
    "col = [\"name\", \"main_category\", \"sub_category\", \"link\", \"no_of_ratings\", \"ratings\", \"actual_price\", \"discount_price\"]\n",
    "df = df.drop_duplicates(subset=col)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fe6ddd63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(473054, 16)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping the duplicate data across categories\n",
    "col = [\"name\", \"link\", \"no_of_ratings\", \"ratings\", \"actual_price\", \"discount_price\"]\n",
    "df = df.drop_duplicates(subset=col)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffc0d6b",
   "metadata": {},
   "source": [
    "**From above data, I could see the length of data stays same so no duplicate data is present.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb71bb9",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a3cbabd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 473054 entries, 0 to 1103\n",
      "Data columns (total 16 columns):\n",
      " #   Column                     Non-Null Count   Dtype  \n",
      "---  ------                     --------------   -----  \n",
      " 0   name                       473054 non-null  object \n",
      " 1   main_category              473054 non-null  object \n",
      " 2   sub_category               473054 non-null  object \n",
      " 3   image                      473054 non-null  object \n",
      " 4   link                       473054 non-null  object \n",
      " 5   ratings                    302401 non-null  float64\n",
      " 6   no_of_ratings              302401 non-null  float64\n",
      " 7   discount_price             416892 non-null  float64\n",
      " 8   actual_price               456433 non-null  float64\n",
      " 9   corrected_rating           302401 non-null  float64\n",
      " 10  t_discount_price           416892 non-null  float64\n",
      " 11  t_actual_price             456433 non-null  float64\n",
      " 12  t_no_of_ratings            302401 non-null  float64\n",
      " 13  is_price_dependency_valid  473054 non-null  bool   \n",
      " 14  is_valid_no_of_ratings     473054 non-null  bool   \n",
      " 15  is_rating_valid            473054 non-null  bool   \n",
      "dtypes: bool(3), float64(8), object(5)\n",
      "memory usage: 51.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cb2a67",
   "metadata": {},
   "source": [
    "**As per above, there is no NaN values in object datatype. But we have made Nan in Numerical columns, so lets check how many zero values are there is each column and check if it is valid or not.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aeaaf6d",
   "metadata": {},
   "source": [
    "**Rating Missing Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b3c7764b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     302401\n",
       "False    170653\n",
       "Name: is_valid_no_of_ratings, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"is_valid_no_of_ratings\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8f37a565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    302401\n",
       "True     170653\n",
       "Name: no_of_ratings, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"no_of_ratings\"].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9abb0728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    302401\n",
       "True     170653\n",
       "Name: ratings, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df[\"ratings\"].isna()).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c91c92",
   "metadata": {},
   "source": [
    "**On Checking we could see no_of_rating have 182027 Nan, There can be products with No ratings given so we can replace them with zero and change corresponding rating info to zero.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bb5f8915",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"no_of_ratings\", \"ratings\"]] = df[[\"no_of_ratings\", \"ratings\"]].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450adf66",
   "metadata": {},
   "source": [
    "#### Price Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "69097692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    456433\n",
       "True      16621\n",
       "Name: actual_price, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"actual_price\"].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f65db52b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    473052\n",
       "True          2\n",
       "Name: actual_price, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df[\"actual_price\"] == 0).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5f402d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    416892\n",
       "True      56162\n",
       "Name: discount_price, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"discount_price\"].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "794d2113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     416892\n",
       "False     56162\n",
       "Name: is_price_dependency_valid, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"is_price_dependency_valid\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3d3d1fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.032299645566866396"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Actual price if it is null/ 0 out of total number of records (%)\n",
    "\n",
    "17816/551585"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb8b4d7",
   "metadata": {},
   "source": [
    "**From above analysis, we could see discount have 61163 of Nan values, but it is valid since there are products with No Discounts.**\n",
    "\n",
    "**But issue is actual_price has 17816 of Nan values, 3 of 0 values, which is not valid, Since they are individual separate products I dont think we can impute data from other products.\n",
    "Also since 17816 is relatively samller(3%) I am dropping those data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cfa416d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Actual Prive nan/0 actual values\n",
    "\n",
    "df = df[~df[\"actual_price\"].isna() & (df[\"actual_price\"] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ed57fa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling Nan in Discount with zero because discoutns can not be nan, it should be zero\n",
    "\n",
    "df.loc[:, \"discount_price\"] = df[\"discount_price\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "307e0227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing all Validation columns\n",
    "\n",
    "cols = [\"is_price_dependency_valid\",\n",
    "       \"is_rating_valid\",\n",
    "        \"is_valid_no_of_ratings\",\n",
    "       \"corrected_rating\",\n",
    "       \"t_discount_price\", \n",
    "        \"t_actual_price\", \n",
    "        \"t_no_of_ratings\"]\n",
    "\n",
    "df = df.drop(cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "903d7222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 456431 entries, 0 to 1103\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   name            456431 non-null  object \n",
      " 1   main_category   456431 non-null  object \n",
      " 2   sub_category    456431 non-null  object \n",
      " 3   image           456431 non-null  object \n",
      " 4   link            456431 non-null  object \n",
      " 5   ratings         456431 non-null  float64\n",
      " 6   no_of_ratings   456431 non-null  float64\n",
      " 7   discount_price  456431 non-null  float64\n",
      " 8   actual_price    456431 non-null  float64\n",
      "dtypes: float64(4), object(5)\n",
      "memory usage: 34.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbd4ec3",
   "metadata": {},
   "source": [
    "**As we can see from above that all the columns have been transformed, now we are getting a clean data with appropriate datatypes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d3b69c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's save the clean data \n",
    "\n",
    "df.to_csv(f\"{project_path}\\\\{clean_file}\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435d89c0",
   "metadata": {},
   "source": [
    "### Let's Load Data to SQL Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "decdd970",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_url = f'DRIVER={driver};Server={server};Port={port}'\n",
    "conn = pyodbc.connect(conn_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "191657cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "curs = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "97763579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refresh DataBase\n",
    "\n",
    "# switch_db = \"use master\"\n",
    "# curs.execute(switch_db)\n",
    "# curs.commit()\n",
    "\n",
    "# drop_db = f\"Drop database if exists {db_name}\"\n",
    "# curs.execute(drop_db)\n",
    "# curs.commit()\n",
    "\n",
    "# create_db = f\"create database {db_name}\"\n",
    "# curs.execute(create_db)\n",
    "# curs.commit()\n",
    "\n",
    "use_db = f\"use {db_name}\"\n",
    "curs.execute(use_db)\n",
    "curs.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "82203e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(df, table_name, curs):\n",
    "    \"\"\"\n",
    "    Function to generate Create Table query\n",
    "    \"\"\"\n",
    "\n",
    "    # DType Mapping For Creating Table\n",
    "    dtype_map = {\n",
    "        \"object\": \"varchar(500)\",\n",
    "        \"category\": \"varchar(50)\",\n",
    "        \"int64\": \"int\",\n",
    "        \"float64\": \"decimal(20, 10)\",\n",
    "        \"datetime64[ns]\": \"date\",\n",
    "    }\n",
    "    \n",
    "    # Replace / with _ in col names\n",
    "    pat = \"/|-| |\\)|\\(\"\n",
    "    \n",
    "    col_to_be_rep = [col for col in df.columns if re.search(pat, col)]\n",
    "    rename_map = {col: re.sub(pat, \"_\", col) for col in col_to_be_rep}\n",
    "    df = df.rename(rename_map, axis=1)\n",
    "\n",
    "    # -------------------------------------Create Table Query Starts------------------------------------------------\n",
    "    create_table_query = f\"\"\"\n",
    "    create table {table_name}(\n",
    "    \"\"\"\n",
    "\n",
    "    # Define Col Types\n",
    "    for col in df.columns:\n",
    "        col_type = f\"\\t{col} {dtype_map[str(df[col].dtypes)]},\\n\"\n",
    "        create_table_query = create_table_query + col_type\n",
    "\n",
    "    create_table_query = create_table_query + \"\\n)\"\n",
    "    \n",
    "    # -------------------------------------Create Table Query Ends------------------------------------------------\n",
    "    \n",
    "    # Execute the Create Table command\n",
    "    curs.execute(create_table_query)\n",
    "    curs.commit()\n",
    "    print(f\"{table_name} created successfully\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3f9d94b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazon_product_v1 created successfully\n"
     ]
    }
   ],
   "source": [
    "create_table(df, table_name=table_name, curs=curs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "35da7fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyodbc.Cursor at 0x1fb07b79c30>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inserting the data from CSV to Table using Batch insert\n",
    "path = f\"{project_path}\\\\{clean_file}\"\n",
    "q = f\"\"\"\n",
    "BULK INSERT dbo.{table_name}\n",
    "FROM '{path}'\n",
    "WITH\n",
    "(\n",
    "        FORMAT='CSV',\n",
    "        FIRSTROW=2\n",
    ");\n",
    "\"\"\"\n",
    "curs.execute(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9107280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "curs.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "57acb79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1 : - Which product category has the highest number of items listed?\n",
    "\n",
    "curs.execute(\n",
    "\"\"\"select\n",
    "main_category\n",
    ",count(main_category) as product_cnt\n",
    "from amazon_product_v1\n",
    "group by main_category\n",
    "order by product_cnt desc\n",
    "\"\"\")\n",
    "\n",
    "query_results = curs.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9c68897c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>main_category</th>\n",
       "      <th>product_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accessories</td>\n",
       "      <td>111171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Women's Clothing</td>\n",
       "      <td>75812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Men's Clothing</td>\n",
       "      <td>73778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TV, Audio And Cameras</td>\n",
       "      <td>66355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Men's Shoes</td>\n",
       "      <td>54863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stores</td>\n",
       "      <td>32334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Appliances</td>\n",
       "      <td>31326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Home And Kitchen</td>\n",
       "      <td>14473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kids' Fashion</td>\n",
       "      <td>13206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sports And Fitness</td>\n",
       "      <td>12253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bags And Luggage</td>\n",
       "      <td>9982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Beauty And Health</td>\n",
       "      <td>9908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Car And Motorbike</td>\n",
       "      <td>6987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Toys And Baby Products</td>\n",
       "      <td>6098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Women's Shoes</td>\n",
       "      <td>5257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Industrial Supplies</td>\n",
       "      <td>4010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Grocery And Gourmet Foods</td>\n",
       "      <td>3282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Pet Supplies</td>\n",
       "      <td>1619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Music</td>\n",
       "      <td>1038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Home, Kitchen, Pets</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                main_category  product_cnt\n",
       "0                 Accessories       111171\n",
       "1            Women's Clothing        75812\n",
       "2              Men's Clothing        73778\n",
       "3       TV, Audio And Cameras        66355\n",
       "4                 Men's Shoes        54863\n",
       "5                      Stores        32334\n",
       "6                  Appliances        31326\n",
       "7            Home And Kitchen        14473\n",
       "8               Kids' Fashion        13206\n",
       "9          Sports And Fitness        12253\n",
       "10           Bags And Luggage         9982\n",
       "11          Beauty And Health         9908\n",
       "12          Car And Motorbike         6987\n",
       "13     Toys And Baby Products         6098\n",
       "14              Women's Shoes         5257\n",
       "15        Industrial Supplies         4010\n",
       "16  Grocery And Gourmet Foods         3282\n",
       "17               Pet Supplies         1619\n",
       "18                      Music         1038\n",
       "19        Home, Kitchen, Pets           17"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's get the data into a dataframe\n",
    "\n",
    "df1 = pd.DataFrame.from_records(data = query_results, columns = ['main_category','product_cnt'])\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "56fba5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2 : - In the \"Electronics\" category, which sub-category has the highest average rating?\n",
    "\n",
    "curs.execute(\"\"\"\n",
    "select\n",
    "sub_category\n",
    ",avg(ratings) as avg_rating\n",
    "from amazon_product_v1\n",
    "where main_category = 'appliances'\n",
    "and ratings != 0 \n",
    "group by sub_category\"\"\")\n",
    "\n",
    "#ignoring rating with 0 since it means no Rating given, I am calculating avg only for product whose ratings given\n",
    "\n",
    "\n",
    "query_results2 = curs.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7ff51ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_category</th>\n",
       "      <th>avg_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Air Conditioners</td>\n",
       "      <td>3.8256484149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heating And Cooling Appliances</td>\n",
       "      <td>3.6906837374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All Appliances</td>\n",
       "      <td>3.9278633623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kitchen And Home Appliances</td>\n",
       "      <td>3.8734088827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Refrigerators</td>\n",
       "      <td>3.9256183745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Washing Machines</td>\n",
       "      <td>3.9927272727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     sub_category    avg_rating\n",
       "0                Air Conditioners  3.8256484149\n",
       "1  Heating And Cooling Appliances  3.6906837374\n",
       "2                  All Appliances  3.9278633623\n",
       "3     Kitchen And Home Appliances  3.8734088827\n",
       "4                   Refrigerators  3.9256183745\n",
       "5                Washing Machines  3.9927272727"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's get the data into a dataframe\n",
    "\n",
    "df2 = pd.DataFrame.from_records(data = query_results2, columns = ['sub_category','avg_rating'])\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "585dcbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3 : -Which product has the highest discount price Among the \"Fashion and Silver Jewellery\" items?\n",
    "\n",
    "curs.execute(\"\"\"\n",
    "select\n",
    "name\n",
    ",discount_price\n",
    "from amazon_product_v1\n",
    "where sub_category = 'fashion and silver jewellery'\n",
    "order by discount_price desc\"\"\")\n",
    "\n",
    "query_results3 = curs.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8e461b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>discount_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Venus Gems Gallery Real Diamond Ring 2 Carat O...</td>\n",
       "      <td>499999.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Krishna Gems Original Diamond VVS1 Clarity 1.8...</td>\n",
       "      <td>204999.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Melorra 22kt 20gm gold coin (916)</td>\n",
       "      <td>122254.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P.C. Chandra Jewellers 22k (916) Yellow Gold N...</td>\n",
       "      <td>88171.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MELORRA Women's 22K 22kt Gold Textured Double ...</td>\n",
       "      <td>85623.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18881</th>\n",
       "      <td>Chandrika Pearls Gems &amp; Jewellers Ganesh Gold ...</td>\n",
       "      <td>0E-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18882</th>\n",
       "      <td>FOURSEVEN-« Number 7 (Seven) Silver Charm - Fi...</td>\n",
       "      <td>0E-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18883</th>\n",
       "      <td>Golden Treasure Traditional Gold Plated Long H...</td>\n",
       "      <td>0E-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18884</th>\n",
       "      <td>Shaya by CaratLane-áHappier than Ever Butterfl...</td>\n",
       "      <td>0E-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18885</th>\n",
       "      <td>Abhooshan Precious Stone Small Nose Pin/Stud w...</td>\n",
       "      <td>0E-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18886 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    name     discount_price\n",
       "0      Venus Gems Gallery Real Diamond Ring 2 Carat O...  499999.0000000000\n",
       "1      Krishna Gems Original Diamond VVS1 Clarity 1.8...  204999.0000000000\n",
       "2                      Melorra 22kt 20gm gold coin (916)  122254.0000000000\n",
       "3      P.C. Chandra Jewellers 22k (916) Yellow Gold N...   88171.0000000000\n",
       "4      MELORRA Women's 22K 22kt Gold Textured Double ...   85623.0000000000\n",
       "...                                                  ...                ...\n",
       "18881  Chandrika Pearls Gems & Jewellers Ganesh Gold ...              0E-10\n",
       "18882  FOURSEVEN-« Number 7 (Seven) Silver Charm - Fi...              0E-10\n",
       "18883  Golden Treasure Traditional Gold Plated Long H...              0E-10\n",
       "18884  Shaya by CaratLane-áHappier than Ever Butterfl...              0E-10\n",
       "18885  Abhooshan Precious Stone Small Nose Pin/Stud w...              0E-10\n",
       "\n",
       "[18886 rows x 2 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's get the data into a dataframe\n",
    "\n",
    "df3 = pd.DataFrame.from_records(data = query_results3, columns = ['name','discount_price'])\n",
    "\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "55206004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4 : -In the \"Home Improvement\" category, which product has the most customer ratings?\n",
    "\n",
    "curs.execute(\"\"\"select top 1\n",
    "name\n",
    ",no_of_ratings\n",
    "from amazon_product_v1\n",
    "where sub_category = 'home improvement'\n",
    "and ratings != 0 \n",
    "order by no_of_ratings desc\"\"\")\n",
    "\n",
    "\n",
    "query_results4 = curs.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cbec6890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>no_of_ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spotzero by Milton Prime Spin Mop with Big Whe...</td>\n",
       "      <td>74689.0000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name     no_of_ratings\n",
       "0  Spotzero by Milton Prime Spin Mop with Big Whe...  74689.0000000000"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's get the data into a dataframe\n",
    "\n",
    "df4 = pd.DataFrame.from_records(data = query_results4, columns = ['name','no_of_ratings'])\n",
    "\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fbd45075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5 : -What is the average discount percentage across all categories?\n",
    "curs.execute(\"\"\"select\n",
    "main_category\n",
    ",avg(discount_price/actual_price) * 100.0 as avg_discount_percent\n",
    "from amazon_product_v1\n",
    "group by main_category\n",
    "order by avg_discount_percent desc\"\"\")\n",
    "\n",
    "\n",
    "query_results5 = curs.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "94347580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>main_category</th>\n",
       "      <th>avg_discount_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home, Kitchen, Pets</td>\n",
       "      <td>76.88399481194023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Grocery And Gourmet Foods</td>\n",
       "      <td>60.07094666422307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Appliances</td>\n",
       "      <td>57.42057549170733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beauty And Health</td>\n",
       "      <td>57.39536676525559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pet Supplies</td>\n",
       "      <td>55.82575309559997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Music</td>\n",
       "      <td>54.66120492304320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Industrial Supplies</td>\n",
       "      <td>53.98037476177771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Toys And Baby Products</td>\n",
       "      <td>53.23752760023941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kids' Fashion</td>\n",
       "      <td>50.96835209864733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TV, Audio And Cameras</td>\n",
       "      <td>49.31159241668294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Men's Shoes</td>\n",
       "      <td>49.23669036957754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Home And Kitchen</td>\n",
       "      <td>49.21960495815428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Car And Motorbike</td>\n",
       "      <td>49.07963279851664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sports And Fitness</td>\n",
       "      <td>48.26900812220240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Men's Clothing</td>\n",
       "      <td>47.78299812592511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Women's Shoes</td>\n",
       "      <td>45.58018933471260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Bags And Luggage</td>\n",
       "      <td>45.09507391751506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Accessories</td>\n",
       "      <td>44.99450606936867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Women's Clothing</td>\n",
       "      <td>38.29365492843302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Stores</td>\n",
       "      <td>37.66959447133886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                main_category avg_discount_percent\n",
       "0         Home, Kitchen, Pets    76.88399481194023\n",
       "1   Grocery And Gourmet Foods    60.07094666422307\n",
       "2                  Appliances    57.42057549170733\n",
       "3           Beauty And Health    57.39536676525559\n",
       "4                Pet Supplies    55.82575309559997\n",
       "5                       Music    54.66120492304320\n",
       "6         Industrial Supplies    53.98037476177771\n",
       "7      Toys And Baby Products    53.23752760023941\n",
       "8               Kids' Fashion    50.96835209864733\n",
       "9       TV, Audio And Cameras    49.31159241668294\n",
       "10                Men's Shoes    49.23669036957754\n",
       "11           Home And Kitchen    49.21960495815428\n",
       "12          Car And Motorbike    49.07963279851664\n",
       "13         Sports And Fitness    48.26900812220240\n",
       "14             Men's Clothing    47.78299812592511\n",
       "15              Women's Shoes    45.58018933471260\n",
       "16           Bags And Luggage    45.09507391751506\n",
       "17                Accessories    44.99450606936867\n",
       "18           Women's Clothing    38.29365492843302\n",
       "19                     Stores    37.66959447133886"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's get the data into a dataframe\n",
    "\n",
    "df5 = pd.DataFrame.from_records(data = query_results5, columns = ['main_category','avg_discount_percent'])\n",
    "\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dfafdd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 6 : -Which product category has the highest average actual price?\n",
    "curs.execute(\"\"\"select\n",
    "main_category\n",
    ",avg(actual_price) as avg_actual_price\n",
    "from amazon_product_v1\n",
    "group by main_category\n",
    "order by avg_actual_price desc\"\"\")\n",
    "\n",
    "query_results6 = curs.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "818a8c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>main_category</th>\n",
       "      <th>avg_actual_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home And Kitchen</td>\n",
       "      <td>685834.5640143715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accessories</td>\n",
       "      <td>8136.3061958604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Appliances</td>\n",
       "      <td>8132.0863327587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sports And Fitness</td>\n",
       "      <td>8084.1154721292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TV, Audio And Cameras</td>\n",
       "      <td>5725.7190181598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Music</td>\n",
       "      <td>5621.8176685934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stores</td>\n",
       "      <td>4959.7710505968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Home, Kitchen, Pets</td>\n",
       "      <td>4468.1176470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bags And Luggage</td>\n",
       "      <td>4047.9072971348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Men's Shoes</td>\n",
       "      <td>3853.4854076517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Industrial Supplies</td>\n",
       "      <td>3446.6634962593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Women's Shoes</td>\n",
       "      <td>2165.0399163020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Toys And Baby Products</td>\n",
       "      <td>1890.9392718924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Men's Clothing</td>\n",
       "      <td>1816.7194793840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Car And Motorbike</td>\n",
       "      <td>1769.9862573350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Women's Clothing</td>\n",
       "      <td>1759.9825743945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kids' Fashion</td>\n",
       "      <td>1659.4847122520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Beauty And Health</td>\n",
       "      <td>1156.5571437222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Pet Supplies</td>\n",
       "      <td>1148.2284002470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Grocery And Gourmet Foods</td>\n",
       "      <td>586.3305149299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                main_category   avg_actual_price\n",
       "0            Home And Kitchen  685834.5640143715\n",
       "1                 Accessories    8136.3061958604\n",
       "2                  Appliances    8132.0863327587\n",
       "3          Sports And Fitness    8084.1154721292\n",
       "4       TV, Audio And Cameras    5725.7190181598\n",
       "5                       Music    5621.8176685934\n",
       "6                      Stores    4959.7710505968\n",
       "7         Home, Kitchen, Pets    4468.1176470588\n",
       "8            Bags And Luggage    4047.9072971348\n",
       "9                 Men's Shoes    3853.4854076517\n",
       "10        Industrial Supplies    3446.6634962593\n",
       "11              Women's Shoes    2165.0399163020\n",
       "12     Toys And Baby Products    1890.9392718924\n",
       "13             Men's Clothing    1816.7194793840\n",
       "14          Car And Motorbike    1769.9862573350\n",
       "15           Women's Clothing    1759.9825743945\n",
       "16              Kids' Fashion    1659.4847122520\n",
       "17          Beauty And Health    1156.5571437222\n",
       "18               Pet Supplies    1148.2284002470\n",
       "19  Grocery And Gourmet Foods     586.3305149299"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's get the data into a dataframe\n",
    "\n",
    "df6 = pd.DataFrame.from_records(data = query_results6, columns = ['main_category','avg_actual_price'])\n",
    "\n",
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2d50bdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 7 : among the \"Grocery and Gourmet Foods\" items, which product has the highest discount percentage?\n",
    "curs.execute(\"\"\"select\n",
    "name\n",
    ",(discount_price/actual_price) * 100.0 as discount_percent\n",
    "from amazon_product_v1\n",
    "where main_category = 'grocery and gourmet foods'\n",
    "order by discount_percent desc\"\"\")\n",
    "\n",
    "query_results7 = curs.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "775897f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>discount_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hakim Suleman's Olive Vinegar (Zaitoon Sirka) ...</td>\n",
       "      <td>99.93333333333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jivo Premium Cold Pressed Kachi Ghani Pure Mus...</td>\n",
       "      <td>99.92000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Berries And Nuts Plain Pista Pouch, 500 g</td>\n",
       "      <td>99.90909090909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DXN Product Noni Juice (450ML)</td>\n",
       "      <td>99.89473684210526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rungtas Real Gold Special Assam Black Tea - 2 ...</td>\n",
       "      <td>99.88888888888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3277</th>\n",
       "      <td>Orchard Lane Organic PERI PERI Tomato Ketchup ...</td>\n",
       "      <td>0E-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3278</th>\n",
       "      <td>Too Yumm Karare Noodle Masala, 75g</td>\n",
       "      <td>0E-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3279</th>\n",
       "      <td>Amazon Brand - Vedaka Fennel Seeds (Saunf), 100 g</td>\n",
       "      <td>0E-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3280</th>\n",
       "      <td>Sumeru Chicken Malai Seekh Kebab, 400 g</td>\n",
       "      <td>0E-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3281</th>\n",
       "      <td>Natureland Organics Brown Sugar 1 Kg (Pack of ...</td>\n",
       "      <td>0E-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3282 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   name   discount_percent\n",
       "0     Hakim Suleman's Olive Vinegar (Zaitoon Sirka) ...  99.93333333333333\n",
       "1     Jivo Premium Cold Pressed Kachi Ghani Pure Mus...  99.92000000000000\n",
       "2             Berries And Nuts Plain Pista Pouch, 500 g  99.90909090909091\n",
       "3                        DXN Product Noni Juice (450ML)  99.89473684210526\n",
       "4     Rungtas Real Gold Special Assam Black Tea - 2 ...  99.88888888888889\n",
       "...                                                 ...                ...\n",
       "3277  Orchard Lane Organic PERI PERI Tomato Ketchup ...              0E-14\n",
       "3278                 Too Yumm Karare Noodle Masala, 75g              0E-14\n",
       "3279  Amazon Brand - Vedaka Fennel Seeds (Saunf), 100 g              0E-14\n",
       "3280            Sumeru Chicken Malai Seekh Kebab, 400 g              0E-14\n",
       "3281  Natureland Organics Brown Sugar 1 Kg (Pack of ...              0E-14\n",
       "\n",
       "[3282 rows x 2 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's get the data into a dataframe\n",
    "\n",
    "df7 = pd.DataFrame.from_records(data = query_results7, columns = ['name','discount_percent'])\n",
    "\n",
    "df7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "24a9cf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 8 :In the \"Sports Fitness and Outdoors\" category, which product has the highest number of customer ratings?\n",
    "\n",
    "curs.execute(\"\"\"select\n",
    "name\n",
    ",no_of_ratings\n",
    "from amazon_product_v1\n",
    "where main_category = 'sports and fitness'\n",
    "order by no_of_ratings desc\"\"\")\n",
    "\n",
    "query_results8 = curs.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "09f9b354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>no_of_ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AmazonBasics 13mm Extra Thick Yoga and Exercis...</td>\n",
       "      <td>74871.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AmazonBasics Neoprene Dumbbells, Set of 2</td>\n",
       "      <td>44728.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kore PVC 10-40 Kg Home Gym Set with One 3 Ft C...</td>\n",
       "      <td>33078.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Campus Men's OXYFIT (N) Walking Shoe</td>\n",
       "      <td>30227.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fitness Mantra-« EVA Yoga Mat for Gym Workout ...</td>\n",
       "      <td>21710.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12248</th>\n",
       "      <td>Jimmy Sports Men's Regular Fit Trackpants|Black</td>\n",
       "      <td>0E-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12249</th>\n",
       "      <td>Fashiol Women Seamless Bra Full Coverage Breat...</td>\n",
       "      <td>0E-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12250</th>\n",
       "      <td>PALAY-« Bucket Hat for Women Men Reversible Fa...</td>\n",
       "      <td>0E-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12251</th>\n",
       "      <td>Skechers Arch FIT - Big Appeal Women's Running...</td>\n",
       "      <td>0E-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12252</th>\n",
       "      <td>Puma Womens Flyer Runner Femme WN's Running Shoe</td>\n",
       "      <td>0E-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12253 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    name     no_of_ratings\n",
       "0      AmazonBasics 13mm Extra Thick Yoga and Exercis...  74871.0000000000\n",
       "1              AmazonBasics Neoprene Dumbbells, Set of 2  44728.0000000000\n",
       "2      Kore PVC 10-40 Kg Home Gym Set with One 3 Ft C...  33078.0000000000\n",
       "3                   Campus Men's OXYFIT (N) Walking Shoe  30227.0000000000\n",
       "4      Fitness Mantra-« EVA Yoga Mat for Gym Workout ...  21710.0000000000\n",
       "...                                                  ...               ...\n",
       "12248    Jimmy Sports Men's Regular Fit Trackpants|Black             0E-10\n",
       "12249  Fashiol Women Seamless Bra Full Coverage Breat...             0E-10\n",
       "12250  PALAY-« Bucket Hat for Women Men Reversible Fa...             0E-10\n",
       "12251  Skechers Arch FIT - Big Appeal Women's Running...             0E-10\n",
       "12252   Puma Womens Flyer Runner Femme WN's Running Shoe             0E-10\n",
       "\n",
       "[12253 rows x 2 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's get the data into a dataframe\n",
    "\n",
    "df8 = pd.DataFrame.from_records(data = query_results8, columns = ['name','no_of_ratings'])\n",
    "\n",
    "df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c13e2d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 9 :.Among the \"Health and Personal Care\" items, which product has the highest average rating?\n",
    "\n",
    "curs.execute(\"\"\"select\n",
    "name\n",
    ",avg(ratings) as avg_rating\n",
    "from amazon_product_v1\n",
    "where sub_category = 'Health and Personal Care'\n",
    "group by name\n",
    "order by avg_rating desc\"\"\")\n",
    "\n",
    "query_results9 = curs.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "df59d295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>avg_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JIPL Neck &amp; Shoulder Relaxer for TMJ Pain | Ne...</td>\n",
       "      <td>5.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bosom Breast Ayurvedic Massage Oil For Women,A...</td>\n",
       "      <td>5.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SAJANI Washing Machine Cleaner Descaler 12 Pac...</td>\n",
       "      <td>5.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PGR Surface &amp; Floor Cleaner Liquid, Floral Fra...</td>\n",
       "      <td>5.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RAWLS Hydrating Under Eye Cream Gel/Enriched w...</td>\n",
       "      <td>5.0000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>RJGUDDU 20g Warts Remover Cream Extract Skin F...</td>\n",
       "      <td>0E-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>Fresh Aloe Vera, 1 Pc</td>\n",
       "      <td>0E-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>Accu-Chek Active 50 Test Strips + 2 packs of l...</td>\n",
       "      <td>0E-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>Neurobion Forte - Strip of 30 Tablets</td>\n",
       "      <td>0E-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>Volini Pain Relief Spray - 60g</td>\n",
       "      <td>0E-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1081 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   name    avg_rating\n",
       "0     JIPL Neck & Shoulder Relaxer for TMJ Pain | Ne...  5.0000000000\n",
       "1     Bosom Breast Ayurvedic Massage Oil For Women,A...  5.0000000000\n",
       "2     SAJANI Washing Machine Cleaner Descaler 12 Pac...  5.0000000000\n",
       "3     PGR Surface & Floor Cleaner Liquid, Floral Fra...  5.0000000000\n",
       "4     RAWLS Hydrating Under Eye Cream Gel/Enriched w...  5.0000000000\n",
       "...                                                 ...           ...\n",
       "1076  RJGUDDU 20g Warts Remover Cream Extract Skin F...         0E-10\n",
       "1077                              Fresh Aloe Vera, 1 Pc         0E-10\n",
       "1078  Accu-Chek Active 50 Test Strips + 2 packs of l...         0E-10\n",
       "1079              Neurobion Forte - Strip of 30 Tablets         0E-10\n",
       "1080                     Volini Pain Relief Spray - 60g         0E-10\n",
       "\n",
       "[1081 rows x 2 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's get the data into a dataframe\n",
    "\n",
    "df9 = pd.DataFrame.from_records(data = query_results9, columns = ['name','avg_rating'])\n",
    "\n",
    "df9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0620439b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 10 :In the \"Kitchen and Dining\" category, which sub-category has the highest number of items listed?\n",
    "\n",
    "curs.execute(\"\"\"select\n",
    "sub_category\n",
    ",count(sub_category) as prod_cnt\n",
    "from amazon_product_v1\n",
    "where main_category = 'home and kitchen'\n",
    "group by sub_category\n",
    "order by prod_cnt desc;\"\"\")\n",
    "\n",
    "\n",
    "query_results10 = curs.fetchall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "293118da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_category</th>\n",
       "      <th>prod_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home Furnishing</td>\n",
       "      <td>1411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Furniture</td>\n",
       "      <td>1301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home D+¬cor</td>\n",
       "      <td>1268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sewing And Craft Supplies</td>\n",
       "      <td>1259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indoor Lighting</td>\n",
       "      <td>1235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>All Home And Kitchen</td>\n",
       "      <td>1220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Home Storage</td>\n",
       "      <td>1220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bedroom Linen</td>\n",
       "      <td>1214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kitchen And Dining</td>\n",
       "      <td>1197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Garden And Outdoors</td>\n",
       "      <td>1098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Home Improvement</td>\n",
       "      <td>1027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Kitchen Storage And Containers</td>\n",
       "      <td>1023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      sub_category  prod_cnt\n",
       "0                  Home Furnishing      1411\n",
       "1                        Furniture      1301\n",
       "2                      Home D+¬cor      1268\n",
       "3        Sewing And Craft Supplies      1259\n",
       "4                  Indoor Lighting      1235\n",
       "5             All Home And Kitchen      1220\n",
       "6                     Home Storage      1220\n",
       "7                    Bedroom Linen      1214\n",
       "8               Kitchen And Dining      1197\n",
       "9              Garden And Outdoors      1098\n",
       "10                Home Improvement      1027\n",
       "11  Kitchen Storage And Containers      1023"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's get the data into a dataframe\n",
    "\n",
    "df10 = pd.DataFrame.from_records(data = query_results10, columns = ['sub_category','prod_cnt'])\n",
    "\n",
    "df10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
